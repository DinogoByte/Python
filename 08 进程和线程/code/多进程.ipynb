{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.7.3 64-bit"
  },
  "metadata": {
   "interpreter": {
    "hash": "aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"
   }
  },
  "interpreter": {
   "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "Python中的多进程\n",
    "-\n",
    "Unix和Linux操作系统上提供了 `fork()`系统调用来创建进程，调用`fork()`函数的是父进程，创建出的是子进程，子进程是父进程的一个拷贝，但是子进程拥有自己的PID。\n",
    "\n",
    "普通的函数调用，调用一次，返回一次，但是fork()调用一次，返回两次，因为操作系统自动把当前进程（称为父进程）复制了一份（称为子进程），然后分别在父进程和子进程内返回。\n",
    "\n",
    "子进程永远返回0，而父进程返回子进程的ID。这样做的理由是，一个父进程可以fork出很多子进程，所以，父进程要记下每个子进程的ID，而子进程只需要调用getppid()就可以拿到父进程的ID。\n",
    "\n",
    "Python的os模块封装了常见的系统调用，其中就包括fork，可以在Python程序中轻松创建子进程："
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "import os\n",
    "\n",
    "print('Process (%s) start...' % os.getpid())\n",
    "# Only works on Unix/Linux/Mac:\n",
    "pid = os.fork()\n",
    "if pid == 0:\n",
    "    print('I am child process (%s) and my parent is %s.' % (os.getpid(), os.getppid()))\n",
    "else:\n",
    "    print('I (%s) just created a child process (%s).' % (os.getpid(), pid))"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "通过结果可以看出来`fork`函数返回了两次\n",
    "\n",
    "Python的os模块提供了`fork()`函数。由于Windows系统没有`fork()`调用，因此要实现跨平台的多进程编程，可以使用`multiprocessing`模块的Process类来创建子进程，而且该模块还提供了更高级的封装，例如批量启动进程的进程池（Pool）、用于进程间通信的队列（Queue）和管道（Pipe）等。\n",
    "\n",
    "### multiprocessing"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# 单进程\n",
    "from random import randint\n",
    "from time import time,sleep\n",
    "\n",
    "def download_task(filename):\n",
    "    print('开始下载%s...' % filename)\n",
    "    time_need = randint(2, 5)\n",
    "    sleep(time_need)\n",
    "    print(f'{filename}下载完成! 耗费了{time_need}秒')\n",
    "\n",
    "def main():\n",
    "    start = time()\n",
    "    download_task('PHP从入门到放弃')\n",
    "    download_task('Python从新手到大师')\n",
    "    end = time()\n",
    "    print('总共花费了%.2f秒' % (end - start))\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    main()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# 多进程\n",
    "from multiprocessing import Process\n",
    "from os import getpid\n",
    "from random import randint\n",
    "from time import time,sleep\n",
    "\n",
    "def download_task(filename):\n",
    "    print('启动下载进程，进程号[%d].' % getpid())\n",
    "    print('开始下载%s...' % filename)\n",
    "    time_need = randint(2, 5)\n",
    "    sleep(time_need)\n",
    "    print(f'{filename}下载完成! 耗费了{time_need}秒')\n",
    "\n",
    "def main():\n",
    "    start = time()\n",
    "    p1 = Process(target=download_task, args=('PHP从入门到放弃',))\n",
    "    p1.start()\n",
    "    p2 = Process(target=download_task, args=('Python从新手到大师',))\n",
    "    p2.start()\n",
    "    p1.join()\n",
    "    p2.join()\n",
    "    end = time()\n",
    "    print('总共花费了%.2f秒' % (end - start))\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    main()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "创建子进程时，只需要传入一个执行函数和函数的参数，创建一个Process实例，用`start()`方法启动，这样创建进程比`fork()`还要简单。\n",
    "\n",
    "`join()`方法可以等待子进程结束后再继续往下运行，通常用于进程间的同步。\n",
    "\n",
    "在上面的代码中，我们通过Process类创建了进程对象，通过target参数我们传入一个函数来表示进程启动后要执行的代码，后面的args是一个元组，它代表了传递给函数的参数。Process对象的start方法用来启动进程，而join方法表示等待进程执行结束。运行上面的代码可以明显发现两个下载任务“同时”启动了，而且程序的执行时间将大大缩短，不再是两个任务的时间总和。下面是程序的一次执行结果。\n",
    "\n",
    "除了multiprocessing模块我们也可以使用subprocess模块中的类和函数来创建和启动子进程，然后通过管道来和子进程通信。 \n",
    "\n",
    "### 进程间通信（Queue）\n",
    "\n",
    "下面我们看下如何实现两个进程间的通信。我们启动两个进程，一个输出Ping，一个输出Pong，两个进程输出的Ping和Pong加起来一共10个。听起来很简单吧，但是如果这样写可是错的哦。"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "from multiprocessing import Process\n",
    "from time import sleep\n",
    "\n",
    "counter = 0\n",
    "\n",
    "def sub_task(string):\n",
    "    global counter\n",
    "    while counter < 10:\n",
    "        print(string, end='', flush=True)\n",
    "        counter += 1\n",
    "        sleep(0.5)\n",
    "\n",
    "        \n",
    "def main():\n",
    "    p1 = Process(target=sub_task, args=('Ping', ))\n",
    "    p1.start()\n",
    "    p2 = Process(target=sub_task, args=('Pong', ))\n",
    "    p2.start()\n",
    "    p1.join()\n",
    "    p2.join()\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    main()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "看起来没毛病，但是最后的结果是Ping和Pong各输出了10个，Why？当我们在程序中创建进程的时候，子进程复制了父进程及其所有的数据结构，每个子进程有自己独立的内存空间，这也就意味着两个子进程中各有一个counter变量，所以结果也就可想而知了。要解决这个问题比较简单的办法是使用multiprocessing模块中的Queue类，它是可以被多个进程共享的队列，底层是通过管道和信号量（semaphore）机制来实现的，大家可以根据下面的例子来修改下。"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Process之间肯定是需要通信的，操作系统提供了很多机制来实现进程间的通信。Python的multiprocessing模块包装了底层的机制，提供了`Queue`、`Pipes`等多种方式来交换数据。\n",
    "\n",
    "我们以Queue为例，在父进程中创建两个子进程，一个往Queue里写数据，一个从Queue里读数据："
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "from multiprocessing import Process, Queue\n",
    "import os, time, random\n",
    "\n",
    "# 写数据进程执行的代码:\n",
    "def write(q):\n",
    "    print('Process to write: %s' % os.getpid())\n",
    "    for value in ['A', 'B', 'C']:\n",
    "        print('Put %s to queue...' % value)\n",
    "        q.put(value)\n",
    "        time.sleep(random.random())\n",
    "\n",
    "# 读数据进程执行的代码:\n",
    "def read(q):\n",
    "    print('Process to read: %s' % os.getpid())\n",
    "    while True:\n",
    "        value = q.get(True)\n",
    "        print('Get %s from queue.' % value)\n",
    "\n",
    "if __name__=='__main__':\n",
    "    # 父进程创建Queue，并传给各个子进程：\n",
    "    q = Queue()\n",
    "    pw = Process(target=write, args=(q,))\n",
    "    pr = Process(target=read, args=(q,))\n",
    "    # 启动子进程pw，写入:\n",
    "    pw.start()\n",
    "    # 启动子进程pr，读取:\n",
    "    pr.start()\n",
    "    # 等待pw结束:\n",
    "    pw.join()\n",
    "    # pr.join()\n",
    "    # pr进程里是死循环，无法等待其结束，只能强行终止:\n",
    "    pr.terminate()\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "在Unix/Linux下，multiprocessing模块封装了fork()调用，使我们不需要关注fork()的细节。由于Windows没有fork调用，因此，multiprocessing需要“模拟”出fork的效果，父进程所有Python对象都必须通过pickle序列化再传到子进程去，所以，如果multiprocessing在Windows下调用失败了，要先考虑是不是pickle失败了。"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Pool\n",
    "如果要启动大量的子进程，可以用进程池的方式批量创建子进程："
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "source": [
    "from multiprocessing import Pool\n",
    "import os, time, random\n",
    "\n",
    "def long_time_task(name):\n",
    "    print('Run task %s (%s)...' % (name, os.getpid()))\n",
    "    start = time.time()\n",
    "    time.sleep(random.random() * 3)  # [0,1)\n",
    "    # time.sleep(random.randint(3,5))\n",
    "    end = time.time()\n",
    "    print('Task %s runs %0.2f seconds.' % (name, (end - start)))\n",
    "\n",
    "if __name__=='__main__':\n",
    "    print('Parent process %s.' % os.getpid())\n",
    "    p = Pool(4)\n",
    "    for i in range(5):\n",
    "        p.apply_async(long_time_task, args=(i,))\n",
    "    print('Waiting for all subprocesses done...')\n",
    "    p.close()\n",
    "    p.join()\n",
    "    print('All subprocesses done.')"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Parent process 91673.\n",
      "Run task 1 (91731)...Run task 2 (91732)...Run task 0 (91730)...Run task 3 (91733)...\n",
      "\n",
      "\n",
      "\n",
      "Task 0 runs 0.10 seconds.\n",
      "Run task 4 (91730)...\n",
      "Waiting for all subprocesses done...\n",
      "Task 4 runs 0.22 seconds.\n",
      "Task 1 runs 1.53 seconds.\n",
      "Task 2 runs 1.82 seconds.\n",
      "Task 3 runs 2.68 seconds.\n",
      "All subprocesses done.\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "代码解读（很好的解读）：\n",
    "\n",
    "对`Pool`对象调用`join()`方法会等待所有子进程执行完毕，调用`join()`之前必须先调用`close()`，调用`close()`之后就不能继续添加新的`Process`了。\n",
    "\n",
    "请注意输出的结果，task `0`，`1`，`2`，`3`是立刻执行的，而task `4`要等待前面某个task完成后才执行，这是因为`Pool`的默认大小是`4`(电脑的CPU数量)，因此，最多同时执行4个进程。这是`Pool`有意设计的限制，**并不是操作系统的限制**。如果改成：\n",
    "```\n",
    "p = Pool(5)\n",
    "```\n",
    "就可以同时跑5个进程。\n",
    "\n",
    "由于Pool的默认大小是CPU的核数，如果你不幸拥有8核CPU，你要提交至少9个子进程才能看到上面的等待效果。\n",
    "\n",
    "> 查看电脑进程数的代码："
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "import multiprocessing\n",
    "\n",
    "print(multiprocessing.cpu_count())"
   ],
   "outputs": [],
   "metadata": {}
  }
 ]
}